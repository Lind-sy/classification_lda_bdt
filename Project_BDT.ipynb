{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Decidion Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets import all libraries that we will later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import csv as csv\n",
    "\n",
    "from random import seed\n",
    "from random import randrange\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First what we do is create a constructor for our class. \n",
    "parameters:\n",
    "    max_tree_lvl - This is the maximum depth of our tree.\n",
    "    min_tree_size - This is the minimum number of training patterns that a given node is responsible for.\n",
    "    seed - is the root node of our tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decidion_Tree():\n",
    "\n",
    "    def __init__(self, max_tree_lvl, min_tree_size):\n",
    "        self.max_tree_lvl = max_tree_lvl\n",
    "        self.min_tree_size = min_tree_size\n",
    "        seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " index - index of sample element that we will compare to given value\n",
    " value - value which determines whether we add current sample elements to one or other class \n",
    " data - all our given data set \n",
    " This method determines how to group our given data samples depending on each samples certain element value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decidion_Tree(Decidion_Tree):    \n",
    "    def split_into_groups(self, index, value, data):\n",
    "        first, second = list(), list()\n",
    "        for row in data:\n",
    "            if row[index] > value:\n",
    "                second.append(row)\n",
    "            else:\n",
    "                first.append(row)\n",
    "        return first, second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " groups - our data samples that have been split into two groups based on a value\n",
    " classes - how many unique class labels do we have \n",
    "\n",
    " First thing what we do is determine how any samples together are in both groups\n",
    " We initialize gini_index - the name of the cost function used to evaluate splits in the data set\n",
    " Now we count how many data samples are in each group \n",
    " If group does not have any samples we continue\n",
    " But if we have data in our group what we do next is calculate: \n",
    "    Gini score that  gives an idea of how good a split is by how mixed the classes are in the two groups created by the split.\n",
    "    for this score first we count how many certain class elements are in group than divide it with all the group sample size\n",
    "    the result is multiplied with itself and added to the score\n",
    "    Next step is gini index calculation where we substract from 1 our score and multiply it with groups sample size devided by all samples size\n",
    "At the end we return gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decidion_Tree(Decidion_Tree):      \n",
    "    def calculate_gini_index(self, groups, classes):\n",
    "        sample_size = float(sum([len(group) for group in groups]))\n",
    "        gini_index = 0.0\n",
    "        for group in groups:\n",
    "            group_sample_size = float(len(group))\n",
    "            score = 0.0\n",
    "            if group_sample_size != 0:\n",
    "                for class_sample in classes:\n",
    "                    p = [row[-1] for row in group].count(class_sample) / group_sample_size\n",
    "                    score += p * p\n",
    "                gini_index += (1.0 - score) * (group_sample_size / sample_size)\n",
    "            else:\n",
    "                continue\n",
    "        return gini_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Data - our data set\n",
    " What this method does is finding the best split for our data set\n",
    " We determine parameters to use to best split our data by into two groups:\n",
    "     what is the best index \n",
    "     what are the best groups \n",
    "     what is the best gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decidion_Tree(Decidion_Tree):      \n",
    "    def split_into_classes(self, data):\n",
    "        class_values = list(set(row[-1] for row in data))\n",
    "        best_index = 100\n",
    "        best_value = 100\n",
    "        best_score = 100\n",
    "        best_groups = None\n",
    "        gini_index = 0\n",
    "        for index in range(len(data[0]) - 1):\n",
    "            for row in data:\n",
    "                groups = self.split_into_groups(index, row[index], data)\n",
    "                gini_index = self.calculate_gini_index(groups, class_values)\n",
    "                if gini_index < best_score:\n",
    "                    best_index, best_value, best_score, best_groups = index, row[index], gini_index, groups\n",
    "        return {'index': best_index, 'value': best_value, 'groups': best_groups, 'gini': gini_index}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " terminal node method is used to determine when to stop growing our tree\n",
    " In other words when we stop growing at a given point, this node is called a terminal node and is used to make a final prediction.\n",
    " In our case 0 or 1\n",
    " Terminal node is calculate by counting how many times each class label in group repeats \n",
    " As terminal node value is take the class label with biggest occurrence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decidion_Tree(Decidion_Tree):      \n",
    "    def set_terminal_value(self, group):\n",
    "        result = [row[-1] for row in group]\n",
    "        return max(set(result), key=result.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now what we do is a recursive tree building \n",
    " First, the two groups of data split by the node are divided into left and right and deleted from the node. \n",
    " As we work on these groups the node no longer requires access to these data.\n",
    " Next, we check if either left or right group of rows is empty \n",
    " and if so we create a terminal node using what records we do have.\n",
    " We then check if we have reached our maximum depth \n",
    " and if so we create a terminal node.\n",
    " We then process the left child, \n",
    " creating a terminal node if the group of rows is too small, \n",
    " otherwise create and add the left node in a depth first\n",
    "  until the bottom of the tree is reached on this branch.\n",
    " The right side is then processed in the same manner, \n",
    " as we rise back up the constructed tree to the root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decidion_Tree(Decidion_Tree):      \n",
    "    def create_tree_structure(self, node, level):\n",
    "        left, right = node['groups']\n",
    "        del (node['groups'])\n",
    "        if not left or not right:\n",
    "            node['left'] = node['right'] = self.set_terminal_value(left + right)\n",
    "            return\n",
    "        if level >= self.max_tree_lvl:\n",
    "            node['left'], node['right'] = self.set_terminal_value(left), self.set_terminal_value(right)\n",
    "            return\n",
    "        if len(left) <= self.min_tree_size:\n",
    "            node['left'] = self.set_terminal_value(left)\n",
    "        else:\n",
    "            node['left'] = self.split_into_classes(left)\n",
    "            self.create_tree_structure(node['left'], level + 1)\n",
    "        if len(right) <= self.min_tree_size:\n",
    "            node['right'] = self.set_terminal_value(right)\n",
    "        else:\n",
    "            node['right'] = self.split_into_classes(right)\n",
    "            self.create_tree_structure(node['right'], level + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now what we do is build a binary decision tree by giving it training data needed to create the tree structure\n",
    " First we divide the training data into classes or in other words find best data split \n",
    " Now we use this data to build our tree using the recursive tree building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decidion_Tree(Decidion_Tree):      \n",
    "    def build_decision_tree(self, train):\n",
    "        root_data = self.split_into_classes(train)\n",
    "        self.create_tree_structure(root_data, 1)\n",
    "        return root_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Testing sample class prediction also happens recursively \n",
    " We decide in which branch to search for our samples call\n",
    " What we do is take a certain sample elements value \n",
    " Based on the index that best describes the class this we calculated when we tried to find the best Gini index\n",
    " Than we do this till we find terminal node which is also our class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decidion_Tree(Decidion_Tree):      \n",
    "    def predict_class(self, node, row):\n",
    "        if row[node['index']] < node['value']:\n",
    "            if isinstance(node['left'], dict):\n",
    "                return self.predict_class(node['left'], row)\n",
    "            else:\n",
    "                return node['left']\n",
    "        else:\n",
    "            if isinstance(node['right'], dict):\n",
    "                return self.predict_class(node['right'], row)\n",
    "            else:\n",
    "                return node['right']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This method is used for classifying our test sample data\n",
    " First we build our tree \n",
    " Than we pass each sample and the tree (created binary decision tree from training data) to predict_class method \n",
    " We return the predicted class and our tree structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decidion_Tree(Decidion_Tree):      \n",
    "    def decision_tree_classifier(self, train, test):\n",
    "        tree = self.build_decision_tree(train)\n",
    "        predictions = list()\n",
    "        for row in test:\n",
    "            prediction = self.predict_class(tree, row)\n",
    "            predictions.append(prediction)\n",
    "        return predictions, tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This is k-fold cross validation to evaluate the performance of the algorithm on the data set.\n",
    " The idea is to divide all our data into small chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decidion_Tree(Decidion_Tree):      \n",
    "    def split_into_validation_data(self, data, chunks):\n",
    "        data_split = list()\n",
    "        data_copy = list(data)\n",
    "        chunk_size = int(len(data) / chunks)\n",
    "        for i in range(chunks):\n",
    "            chunk = list()\n",
    "            while len(chunk) < chunk_size:\n",
    "                index = randrange(len(data_copy))\n",
    "                chunk.append(data_copy.pop(index))\n",
    "            data_split.append(chunk)\n",
    "        return data_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This method is used to measure how good our binary decision tree is working \n",
    " we count all the correctly found labels \n",
    " Then divide them with actual label number and multiply with 100 to get percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decidion_Tree(Decidion_Tree):      \n",
    "    def prediction_accuracy(self, actual_labels, predicted_labels):\n",
    "        counter = 0\n",
    "        for i in range(len(actual_labels)):\n",
    "            if actual_labels[i] == predicted_labels[i]:\n",
    "                counter += 1\n",
    "        return counter / float(len(actual_labels)) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This method is used for reading our data set from a file\n",
    " We will get a list of data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decidion_Tree(Decidion_Tree):      \n",
    "    def loadDataSet(self, filename, data=[]):\n",
    "        with open(filename, 'r') as csvfile:\n",
    "            lines = csv.reader(csvfile)\n",
    "            dataset = list(lines)\n",
    "            for x in range(len(dataset)):\n",
    "                dataset[x] = [float(i) for i in dataset[x]]\n",
    "                data.append(dataset[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In main function we determine the maximum tree depth, minimum nodes a tree can have\n",
    " chunk size for cross validation\n",
    " Next we build a tree, load our data set \n",
    " split data set into 6 chunks\n",
    " Now what we do is change which data chunks we use for training and which data chunk we use for testing to test our tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Scores: [100.0, 100.0, 100.0, 100.0, 93.75, 93.75]\nMean Accuracy: 97.917%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data = []\n",
    "    filename = 'iris_data.csv'\n",
    "    \n",
    "    chunks = 6\n",
    "    max_tree_lvl = 4\n",
    "    min_tree_size = 10\n",
    "    binary_tree = Decidion_Tree(max_tree_lvl, min_tree_size)\n",
    "    binary_tree.loadDataSet(filename, data)\n",
    "    chunks = binary_tree.split_into_validation_data(data, chunks)\n",
    "    class_scores = list()\n",
    "    for i in range(6):\n",
    "        train_data = list(chunks)\n",
    "        train_data.remove(chunks[i])\n",
    "        train_data = sum(train_data, [])\n",
    "        test_data = list()\n",
    "        for row in chunks[i]:\n",
    "            row_copy = list(row)\n",
    "            test_data.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted, tree = binary_tree.decision_tree_classifier(train_data, test_data)\n",
    "        actual = [row[-1] for row in chunks[i]]\n",
    "        accuracy = binary_tree.prediction_accuracy(actual, predicted)\n",
    "        class_scores.append(accuracy)\n",
    "\n",
    "    print('Class Scores: %s' % class_scores)\n",
    "    print('Mean Accuracy: %.3f%%' % (sum(class_scores) / float(len(class_scores))))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
